{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_data_transfrom.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSmFpN5jLbbT",
        "colab_type": "text"
      },
      "source": [
        "# LA Metro Bike System (Bike Sharing System)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx7WAlYIzflb",
        "colab_type": "text"
      },
      "source": [
        "Link the Google Drive with the Colab, to access data files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trtpq1uuiIfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3cd64319-7725-495c-abe0-95de3e080e7c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8aMDMcpL2th",
        "colab_type": "text"
      },
      "source": [
        "Installing the libraries required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHZC11fTVe_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os import listdir, makedirs, remove\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "from numpy.random import Generator, PCG64"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSkE_mogKoVU",
        "colab_type": "text"
      },
      "source": [
        "### Data Processing and Transformation \n",
        "This process consists of functions developed to faciliate creation of the desired dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOg1p-9qfgNi",
        "colab_type": "text"
      },
      "source": [
        "1. \"time_bins\" function creates a dataframe of start date time and end date time with interval size and returns it, to where the function is called."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Hi0tzCVrTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def time_bins(start_date, end_date, interval_size):\n",
        "  \n",
        "    start = datetime.strptime(start_date, '%Y/%m/%d')\n",
        "    end = datetime.strptime(end_date, '%Y/%m/%d')\n",
        "    gap = timedelta(minutes=interval_size)\n",
        "\n",
        "    interval_id = 0\n",
        "    outer_limit = start\n",
        "    vals = []\n",
        "    while outer_limit < end:\n",
        "        inner_limit = outer_limit\n",
        "        outer_limit += gap\n",
        "        i = [interval_id, inner_limit.strftime('%d/%m/%Y %H:%M'),\n",
        "                      outer_limit.strftime('%d/%m/%Y %H:%M')]\n",
        "        vals.append(pd.Series(i))\n",
        "        interval_id += 1\n",
        "\n",
        "    df_out = pd.DataFrame(vals)\n",
        "    df_out = df_out.rename(columns={0: 'interval_id', 1: 'inner_limit', 2: 'outer_limit'})\n",
        "    df_out['inner_limit'] = pd.to_datetime(df_out['inner_limit'], dayfirst=True)\n",
        "    df_out['outer_limit'] = pd.to_datetime(df_out['outer_limit'], dayfirst=True)\n",
        "\n",
        "    return df_out"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPlb0LDFkruo",
        "colab_type": "text"
      },
      "source": [
        "2. \"format_data\" function loads the bike trip data, one file at a time and performs pre-preprocessing on it. And at end combines it with the time interval dataset obtained from \"time_bins\" function to develop transformed dataset and weights for graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQFiUk97VzCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_data(file_path, tinterval, interval_size, duration_upper, station_exclude, station_const_ids):\n",
        "  \n",
        "    def round_minutes(dt, direction, resolution):\n",
        "        new_minute = (dt.minute // resolution + (1 if direction == 'up' else 0)) * resolution\n",
        "        return dt + timedelta(minutes=new_minute - dt.minute)\n",
        "\n",
        "    # Read bike trip data and load it into a pandas dataframe.\n",
        "    df_raw = pd.read_csv(file_path, low_memory= False)\n",
        "    df_raw['End Date'] = pd.to_datetime(df_raw['end_time'], dayfirst=True)\n",
        "    df_raw['Start Date'] = pd.to_datetime(df_raw['start_time'], dayfirst=True)\n",
        "    df_raw = df_raw.rename(columns={'end_station' : 'EndStation Id', 'start_station': 'StartStation Id', 'duration': 'Duration'})\n",
        "    df_raw = df_raw[~df_raw['EndStation Id'].isna()]\n",
        "    df_raw['EndStation Id'] = df_raw['EndStation Id'].astype(int)\n",
        "    df_raw['StartStation Id'] = df_raw['StartStation Id'].astype(int)\n",
        "    df_raw = df_raw.loc[df_raw['Duration'] < duration_upper]\n",
        "\n",
        "    # Check to confirm no unknown station value is present in the data which is not recorded in bike station details dataset.\n",
        "    s_diff = set(df_raw['StartStation Id'].to_list()) - station_const_ids\n",
        "    e_diff = set(df_raw['EndStation Id'].to_list()) - station_const_ids\n",
        "    if len(s_diff) > 0:\n",
        "        raise RuntimeError('In file {} unknown start station IDs: {}'.format(file_path, s_diff))\n",
        "    if len(e_diff) > 0:\n",
        "        raise RuntimeError('In file {} unknown end station IDs: {}'.format(file_path, e_diff))\n",
        "\n",
        "    # Remove unwanted stations like virtual stations\n",
        "    df_raw = df_raw.loc[~df_raw['StartStation Id'].isin(station_exclude)]\n",
        "    df_raw = df_raw.loc[~df_raw['EndStation Id'].isin(station_exclude)]\n",
        "\n",
        "    # Count the number of bike trips made for station-to-station.\n",
        "    df_graph_weight = df_raw.groupby(['StartStation Id', 'EndStation Id']).size()\n",
        "\n",
        "    # Maps time of bike trip to a starting time of the interval, as defined by the dataset created by time_bins().\n",
        "    df_raw['End Date Lower Bound'] = df_raw['End Date'].apply(round_minutes,\n",
        "                                                              **{'direction': 'down', 'resolution': interval_size})\n",
        "    df_raw['Start Date Lower Bound'] = df_raw['Start Date'].apply(round_minutes,\n",
        "                                                                  **{'direction': 'down', 'resolution': interval_size})\n",
        "\n",
        "    \n",
        "    #Merge df_raw dataset with time interval dataset obtained from the time_bins().\n",
        "    df1 = pd.merge(df_raw, tinterval, left_on='End Date Lower Bound', right_on='inner_limit').drop(\n",
        "        columns=['inner_limit', 'outer_limit'])\n",
        "    df1 = df1.rename({'interval_id': 'End Date ID'}, axis=1)\n",
        "    df1 = pd.merge(df1, tinterval, left_on='Start Date Lower Bound', right_on='inner_limit').drop(\n",
        "        columns=['inner_limit', 'outer_limit'])\n",
        "    df1 = df1.rename({'interval_id': 'Start Date ID'}, axis=1)\n",
        "    df1 = df1.drop(columns=['bike_id', 'Duration', 'passholder_type','plan_duration','start_lon','start_lat',\n",
        "                          'End Date','Start Date', 'trip_route_category','bike_type','end_lat', 'end_lon',\n",
        "                          'End Date Lower Bound', 'Start Date Lower Bound'])\n",
        "    # Raises an error\n",
        "    if len(df1) == 0:\n",
        "        raise RuntimeError('Incorrect time intervals for file {}'.format(file_path))\n",
        "\n",
        "    g_arrival = df1.groupby(by=['EndStation Id', 'End Date ID'])\n",
        "    df_arrival = g_arrival.size()\n",
        "    g_departure = df1.groupby(by=['StartStation Id', 'Start Date ID'])\n",
        "    df_departure = g_departure.size()\n",
        "\n",
        "    # Zero is substituted in place of records with missing value of time ids,  \n",
        "    s1 = df_arrival.index.get_level_values('EndStation Id').unique()\n",
        "    s2 = df_departure.index.get_level_values('StartStation Id').unique()\n",
        "    s_index = s1.union(s2)\n",
        "    t1 = df_arrival.index.get_level_values('End Date ID').min()\n",
        "    t2 = df_departure.index.get_level_values('Start Date ID').max()\n",
        "    t_index = pd.Int64Index(list(range(t1, t2 + 1)), dtype='int64')\n",
        "    new_index = pd.MultiIndex.from_product([s_index, t_index],\n",
        "                                           names=['station_id', 'time_id'])\n",
        "    df_arrival = pd.DataFrame(df_arrival.reindex(new_index, fill_value=0), columns=['docks_demand'])\n",
        "    df_departure = pd.DataFrame(df_departure.reindex(new_index, fill_value=0), columns=['bikes_demand'])\n",
        "\n",
        "    df_all = df_arrival.join(df_departure, how='outer')\n",
        "\n",
        "    return df_all, df_graph_weight\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGcjWbibWDVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_data(file_name_root, max_file_index, t_interval):\n",
        "\n",
        "    drop_index = None\n",
        "    df_all = []\n",
        "\n",
        "    #iterating every files to remove duplicate element\n",
        "    for ind in range(max_file_index):\n",
        "        df = pd.read_csv('{}_{}.csv'.format(file_name_root, ind), index_col=(0, 1))\n",
        "        for ind_ in range(ind + 1, max_file_index):\n",
        "            print('Processing file pair {}-{} of {}'.format(ind, ind_, max_file_index))\n",
        "            df1 = pd.read_csv('{}_{}.csv'.format(file_name_root, ind_), index_col=(0, 1))\n",
        "            df2 = df.join(df1, how='inner', lsuffix='_0', rsuffix='_1')\n",
        "\n",
        "            # If time-place coordinate overlap found put coordinates in new common file\n",
        "            if len(df2) > 0:\n",
        "                df2['docks_demand'] = df2['docks_demand_0'] + df2['docks_demand_1']\n",
        "                df2['bikes_demand'] = df2['bikes_demand_0'] + df2['bikes_demand_1']\n",
        "                df2 = df2.drop(['docks_demand_0', 'docks_demand_1', 'bikes_demand_0', 'bikes_demand_1'], axis=1)\n",
        "                df_all.append(df2)\n",
        "\n",
        "                if drop_index is None:\n",
        "                    drop_index = df2.index\n",
        "                else:\n",
        "                    drop_index = drop_index.union(df2.index)\n",
        "\n",
        "    # Drops duplicatte records and the collective data from all the files is saved.\n",
        "    for ind in range(max_file_index):\n",
        "        df = pd.read_csv('{}_{}.csv'.format(file_name_root, ind), index_col=(0, 1))\n",
        "\n",
        "        if not drop_index is None:\n",
        "            df = df[~df.index.isin(drop_index)]\n",
        "        df_all.append(df)\n",
        "\n",
        "    df_all = pd.concat(df_all)\n",
        "    df_all.reset_index(level=0, inplace=True)\n",
        "    df_all.reset_index(level=0, inplace=True)\n",
        "\n",
        "    df_all.to_csv('/content/drive/My Drive/data_int_{}/'.format(t_interval)+ 'metro_formated_data.csv', index=False)\n",
        "\n",
        "    return list(df_all['station_id'].unique())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWBbgWLeWNyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_graph_weights(graphs, stations_include, norm='median'):\n",
        "\n",
        "    # Create index that contains all station pairs that ever appears in the raw data files\n",
        "    # and apply this index to all graphs.\n",
        "    mega_index = graphs[0].index\n",
        "    for graph in graphs[1:]:\n",
        "        mega_index = mega_index.union(graph.index)\n",
        "    g_expand = [g.reindex(mega_index, fill_value=0) for g in graphs]\n",
        "    cat_graph = pd.concat(g_expand).reset_index()\n",
        "\n",
        "    cat_graph = cat_graph.loc[cat_graph['StartStation Id'].isin(stations_include)]\n",
        "    cat_graph = cat_graph.loc[cat_graph['EndStation Id'].isin(stations_include)]\n",
        "\n",
        "    cat_graph_all = cat_graph.groupby(['StartStation Id', 'EndStation Id']).sum()\n",
        "    cat_graph_all = cat_graph_all.rename(columns={0: 'total'})\n",
        "\n",
        "    all_df = []\n",
        "    #Create another feature in the form of percentage of usage.\n",
        "    for s_ind, df_slice in cat_graph_all.groupby('StartStation Id'):\n",
        "        mean_slice = df_slice['total'].sum()\n",
        "        df_slice.loc[:, 'average_percent'] = 100.0 * df_slice['total'] / mean_slice\n",
        "        all_df.append(df_slice)\n",
        "    cat_graph_all = pd.concat(all_df)\n",
        "\n",
        "    return cat_graph_all\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIwHymTFWZC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_data(raw_data_file_paths, time_interval_size, lower_t_bound, upper_t_bound,\n",
        "         duration_upper, stations_exclude, station_filename):\n",
        "    # Create a time interval id mapping to real-world times\n",
        "    tinterval = time_bins(lower_t_bound, upper_t_bound, time_interval_size)\n",
        "\n",
        "    tinterval.to_csv('/content/drive/My Drive/data_int_{}/tinterval.csv'.format(time_interval_size))\n",
        "\n",
        "    # Load station dataset\n",
        "    stations_const = pd.read_csv(station_filename)\n",
        "    stations_const_ids = set(stations_const['Station_ID'].to_list())\n",
        "\n",
        "    # Format multiple bike trip data files\n",
        "    graphs = []\n",
        "    for k, file_path in enumerate(raw_data_file_paths):\n",
        "        print('Processing... {}'.format(file_path))\n",
        "        spatiotemp, graph_weights = format_data(file_path, tinterval, time_interval_size,\n",
        "                                                       duration_upper, stations_exclude, stations_const_ids)\n",
        "        spatiotemp.to_csv('/content/drive/My Drive/data_int_{}/data_reformat_{}.csv'.format(time_interval_size,k))\n",
        "        graphs.append(graph_weights)\n",
        "\n",
        "    stations_include = merge_data('/content/drive/My Drive/data_int_{}/data_reformat'.format(time_interval_size), k + 1, time_interval_size)\n",
        "    print(stations_include)\n",
        "\n",
        "    # Put together the graph weight data\n",
        "    df_graph_all = make_graph_weights(graphs, stations_include)\n",
        "    print(df_graph_all)\n",
        "    df_graph_all.to_csv('/content/drive/My Drive/data_int_{}/graph_weight.csv'.format(time_interval_size))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVEXup_H_J_L",
        "colab_type": "text"
      },
      "source": [
        "### 60 min time interval formed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmgHQjgAWaWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "5583fa1d-3513-4dcd-b525-16a6a8a4068f"
      },
      "source": [
        "# File paths to raw data files\n",
        "files = os.listdir('/content/drive/My Drive/Bikedata')\n",
        "metro_files = ['/content/drive/My Drive/Bikedata/{}'.format(fp) for fp in files]\n",
        "\n",
        "# Number of minutes of a time interval \n",
        "#For this experiment two interval size is tested 30min and 60 min\n",
        "Interval = 60\n",
        "\n",
        "# Start and End of the time period of data (YYYY/MM/DD)\n",
        "start_period = '2019/01/01'\n",
        "end_period = '2020/01/01'\n",
        "\n",
        "# To exclude any outliers\n",
        "limit = 30000\n",
        "\n",
        "# To remove any bike station. \n",
        "station_drop = []\n",
        "\n",
        "# Bike station in station dataset\n",
        "station_df = '/content/drive/My Drive/metro-bike-share-stations-2020-04-01.csv'\n",
        "\n",
        "# Creates a new directory and stores the dataset.\n",
        "os.mkdir('/content/drive/My Drive/data_int_{}'.format(Interval))\n",
        "transform_data(metro_files, Interval, start_period, end_period, limit, station_drop, station_df)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing... /content/drive/My Drive/Bikedata/metro-bike-share-trips-2019-q1.csv\n",
            "Processing... /content/drive/My Drive/Bikedata/metro-bike-share-trips-2019-q3.csv\n",
            "Processing... /content/drive/My Drive/Bikedata/metro-bike-share-trips-2019-q2.csv\n",
            "Processing... /content/drive/My Drive/Bikedata/metro-bike-share-trips-2019-q4.csv\n",
            "Processing file pair 0-1 of 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing file pair 0-2 of 4\n",
            "Processing file pair 0-3 of 4\n",
            "Processing file pair 1-2 of 4\n",
            "Processing file pair 1-3 of 4\n",
            "Processing file pair 2-3 of 4\n",
            "[3000, 3005, 3006, 3007, 3008, 3010, 3011, 3013, 3014, 3016, 3018, 3019, 3020, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3040, 3042, 3045, 3046, 3047, 3048, 3049, 3051, 3052, 3054, 3056, 3057, 3058, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3074, 3075, 3076, 3077, 3078, 3081, 3082, 4125, 4126, 4127, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4220, 4227, 4245, 4246, 4248, 4249, 4250, 4254, 4266, 4267, 4273, 4275, 4285, 4286, 4293, 4300, 4304, 4306, 4311, 4312, 4313, 4314, 4315, 4322, 4323, 4324, 4325, 4328, 4329, 4330, 4331, 4332, 4333, 4334, 4335, 4336, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4372, 4378, 4379, 4380, 4381, 4382, 4385, 4373, 4374, 4247, 4301, 4302, 4303, 4337, 4383, 4387, 4389, 4390, 4393, 4394, 4395, 4396, 4397, 4400, 4401, 4404, 4405, 4408, 4409, 4410, 3079, 4338, 4384, 4406, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4422, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4435, 4436, 4437, 4438, 4440, 4441, 4442, 4443, 4444, 4445, 4449, 4453, 4202, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4356, 4357, 4369, 4402, 4407, 4439, 4446, 4447, 4448, 4450, 4451, 4452, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4469, 4470, 4472, 4473, 4480, 4482, 4483, 4484, 4490, 4491, 4493]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                               total  average_percent\n",
            "StartStation Id EndStation Id                        \n",
            "3000            3000             154        30.800000\n",
            "                3005               1         0.200000\n",
            "                3006               1         0.200000\n",
            "                3007               2         0.400000\n",
            "                3010               3         0.600000\n",
            "...                              ...              ...\n",
            "4493            4453               2         6.451613\n",
            "                4455               3         9.677419\n",
            "                4473               1         3.225806\n",
            "                4483               3         9.677419\n",
            "                4493               2         6.451613\n",
            "\n",
            "[10232 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Ta4HBuDj8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "d643fef8-47f1-4d8b-a5ad-0586a0b57e61"
      },
      "source": [
        "transform_data = pd.read_csv('/content/drive/My Drive/data_int_60/metro_formated_data.csv')\n",
        "transform_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_id</th>\n",
              "      <th>station_id</th>\n",
              "      <th>docks_demand</th>\n",
              "      <th>bikes_demand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>144</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>145</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>147</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   time_id  station_id  docks_demand  bikes_demand\n",
              "0      144        3000             0             0\n",
              "1      145        3000             0             0\n",
              "2      146        3000             0             0\n",
              "3      147        3000             0             0\n",
              "4      148        3000             0             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw7jKp3XD1No",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "d91f17af-a55e-4308-8119-d21d9f87e783"
      },
      "source": [
        "time_int_data = pd.read_csv('/content/drive/My Drive/data_int_30/tinterval.csv')\n",
        "time_int_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>interval_id</th>\n",
              "      <th>inner_limit</th>\n",
              "      <th>outer_limit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-01-01 00:00:00</td>\n",
              "      <td>2019-01-01 00:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-01-01 00:30:00</td>\n",
              "      <td>2019-01-01 01:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2019-01-01 01:00:00</td>\n",
              "      <td>2019-01-01 01:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2019-01-01 01:30:00</td>\n",
              "      <td>2019-01-01 02:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-01-01 02:00:00</td>\n",
              "      <td>2019-01-01 02:30:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  interval_id          inner_limit          outer_limit\n",
              "0           0            0  2019-01-01 00:00:00  2019-01-01 00:30:00\n",
              "1           1            1  2019-01-01 00:30:00  2019-01-01 01:00:00\n",
              "2           2            2  2019-01-01 01:00:00  2019-01-01 01:30:00\n",
              "3           3            3  2019-01-01 01:30:00  2019-01-01 02:00:00\n",
              "4           4            4  2019-01-01 02:00:00  2019-01-01 02:30:00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdkwqN3DnCU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "2f2a39d3-dca5-484f-d454-f1e89c218c34"
      },
      "source": [
        "time_int_data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>interval_id</th>\n",
              "      <th>inner_limit</th>\n",
              "      <th>outer_limit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17515</th>\n",
              "      <td>17515</td>\n",
              "      <td>17515</td>\n",
              "      <td>2019-12-31 21:30:00</td>\n",
              "      <td>2019-12-31 22:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17516</th>\n",
              "      <td>17516</td>\n",
              "      <td>17516</td>\n",
              "      <td>2019-12-31 22:00:00</td>\n",
              "      <td>2019-12-31 22:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17517</th>\n",
              "      <td>17517</td>\n",
              "      <td>17517</td>\n",
              "      <td>2019-12-31 22:30:00</td>\n",
              "      <td>2019-12-31 23:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17518</th>\n",
              "      <td>17518</td>\n",
              "      <td>17518</td>\n",
              "      <td>2019-12-31 23:00:00</td>\n",
              "      <td>2019-12-31 23:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17519</th>\n",
              "      <td>17519</td>\n",
              "      <td>17519</td>\n",
              "      <td>2019-12-31 23:30:00</td>\n",
              "      <td>2020-01-01 00:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  interval_id          inner_limit          outer_limit\n",
              "17515       17515        17515  2019-12-31 21:30:00  2019-12-31 22:00:00\n",
              "17516       17516        17516  2019-12-31 22:00:00  2019-12-31 22:30:00\n",
              "17517       17517        17517  2019-12-31 22:30:00  2019-12-31 23:00:00\n",
              "17518       17518        17518  2019-12-31 23:00:00  2019-12-31 23:30:00\n",
              "17519       17519        17519  2019-12-31 23:30:00  2020-01-01 00:00:00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzTVuo67EEDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "02ab63ac-bec1-47b5-9ac6-b7cefa948262"
      },
      "source": [
        "graph_wt_data = pd.read_csv('/content/drive/My Drive/data_int_60/graph_weight.csv')\n",
        "graph_wt_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StartStation Id</th>\n",
              "      <th>EndStation Id</th>\n",
              "      <th>total</th>\n",
              "      <th>average_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3000</td>\n",
              "      <td>3000</td>\n",
              "      <td>154</td>\n",
              "      <td>30.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3000</td>\n",
              "      <td>3005</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3000</td>\n",
              "      <td>3006</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3000</td>\n",
              "      <td>3007</td>\n",
              "      <td>2</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3000</td>\n",
              "      <td>3010</td>\n",
              "      <td>3</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   StartStation Id  EndStation Id  total  average_percent\n",
              "0             3000           3000    154             30.8\n",
              "1             3000           3005      1              0.2\n",
              "2             3000           3006      1              0.2\n",
              "3             3000           3007      2              0.4\n",
              "4             3000           3010      3              0.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}